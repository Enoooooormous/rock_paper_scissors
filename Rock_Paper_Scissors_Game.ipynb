{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all packages needed to run the notebook\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import keras \n",
    "from keras import applications\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files       \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import ndimage \n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART I: Building the tools the applications will rely on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_hand(bg, roi):\n",
    "    _ , thresholded = cv2.threshold(bg, 125, 255, cv2.THRESH_BINARY)\n",
    "    _, hand_binary = cv2.threshold(roi, 125, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    diff = cv2.absdiff(thresholded, hand_binary)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i in range(0,len(contours)):\n",
    "        if hierarchy[0][i][3] == -1:\n",
    "            cv2.drawContours(diff, contours, i, (125,125,125), 5)\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(frame, diff, num_frames):\n",
    "    if num_frames >= 50 and num_frames < 200:\n",
    "        cv2.putText(frame, \"Make a paper\", (0, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255), 2)\n",
    "        \n",
    "    if num_frames >= 100 and num_frames < 200:\n",
    "        file_name_path = 'C:\\\\Users\\\\rock_paper_scissors\\\\paper\\\\' + str(num_frames) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, diff)\n",
    "    \n",
    "    if num_frames >= 200 and num_frames < 350:\n",
    "        cv2.putText(frame, \"Make a rock\", (0, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255), 2)\n",
    "        \n",
    "    if num_frames >= 250 and num_frames < 350:\n",
    "        file_name_path = 'C:\\\\Users\\\\rock_paper_scissors\\\\rock\\\\' + str(num_frames) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, diff)\n",
    "    \n",
    "    if num_frames >= 350 and num_frames < 500:\n",
    "        cv2.putText(frame, \"Make a scissors\", (0, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255), 2)\n",
    "        \n",
    "    if num_frames >= 400 and num_frames < 500:\n",
    "        file_name_path = 'C:\\\\Users\\\\rock_paper_scissors\\\\scissors\\\\' + str(num_frames) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, diff)\n",
    "        \n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the training images for the classifier (rock, paper, scissors, other)\n",
    "\n",
    "\n",
    "# Specify the variables to identify the ROI\n",
    "x1, x2 = 75, 460\n",
    "y1, y2 = 400, 640\n",
    "\n",
    "# Create a None variable which will become the background (for background substraction)\n",
    "bg = None\n",
    "\n",
    "# Open the stream video\n",
    "cam = cv2.VideoCapture(0)\n",
    "num_frames = 0\n",
    "\n",
    "# Keep looping, until interrupted\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Flip the frame so that it is not the mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Draw a rectangle to indicate the ROI\n",
    "    frame = cv2.rectangle(frame, (y1,x1), (y2,x2), (255,255,255), 3)\n",
    "    \n",
    "    # Get first image as background\n",
    "    if bg is None:\n",
    "        bg = cv2.cvtColor(frame[x1:x2,y1:y2], cv2.COLOR_BGR2GRAY)\n",
    "        bg = cv2.GaussianBlur(bg, (7,7), 0)\n",
    "        \n",
    "    roi = frame[x1:x2,y1:y2]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    roi = cv2.GaussianBlur(roi, (7,7), 0)\n",
    "    \n",
    "    # Use the BG and ROI to identify the hand gesture\n",
    "    diff = identify_hand(bg, roi)\n",
    "    \n",
    "    # Save the image to train the classifier later on\n",
    "    frame = save_image(frame, diff, num_frames)\n",
    "            \n",
    "    # Count the frames to know when to change gesture    \n",
    "    num_frames += 1\n",
    "    \n",
    "    # Show the output\n",
    "    cv2.imshow('Game', frame)\n",
    "    cv2.imshow('Hand',diff)\n",
    "\n",
    "    # Close windows with Enter\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 13:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the augmentation process (of the training data)\n",
    "\n",
    "\n",
    "# Defining a set of functions to load the data\n",
    " \n",
    "nb_category = 3\n",
    "\n",
    "# Import data and output image file and target file \n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    img_files = np.array(data['filenames'])\n",
    "    img_targets = np_utils.to_categorical(np.array(data['target']), nb_category)\n",
    "    return img_files, img_targets\n",
    "\n",
    "# Convert the image file into a tensor format\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(240, 240))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (240, 240, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 240, 240, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "# Loop over a series of images\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "# Creating separate folders to host the created images (can also be skipped to add the images directly to the original files) \n",
    "\n",
    "# Go through the original files and extract the target name\n",
    "category_names = [item[52:-1] for item in sorted(glob('C:/Users/rock_paper_scissors/*/'))]\n",
    "\n",
    "# Create a file for each category name (to host augmented images of that category)\n",
    "for cat in category_names:\n",
    "    os.makedirs(\"C:/Users/img_created_{}\".format(cat))\n",
    "\n",
    "print(category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating new images from original data\n",
    "\n",
    "\n",
    "# Load the original dataset\n",
    "img, targets = load_dataset('C:\\\\Users\\\\rock_paper_scissors')\n",
    "\n",
    "# Group images by target\n",
    "for cat in category_names:\n",
    "    index = []\n",
    "    for i in range(0,len(targets)):\n",
    "            ind = [category_names[np.argmax(targets[i])] == cat]\n",
    "            index.append(ind)\n",
    "            indexes = np.concatenate(np.asarray(index))\n",
    "\n",
    "    img_to_create = img[indexes]\n",
    "    img_to_tensor = paths_to_tensor(img_to_create)/255\n",
    "\n",
    "    \n",
    "    # Perform the transformation\n",
    "    datagen = ImageDataGenerator(zca_whitening=True,\n",
    "                                 zca_epsilon=1e-3,\n",
    "                                 rotation_range=20,\n",
    "                                 width_shift_range=0.15,\n",
    "                                 height_shift_range=0.15,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "\n",
    "    i=0\n",
    "    for batch in datagen.flow(img_to_tensor,\n",
    "                              batch_size=50,\n",
    "                              shuffle=True,\n",
    "                              save_to_dir= \"C:/Users/img_created_{}\".format(cat),\n",
    "                              save_format='jpeg'):\n",
    "        i +=1\n",
    "        if i >10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating and training the deep learning model for sign recognition\n",
    "\n",
    "# Loading the dataset and separating into train, validation and test set\n",
    "img, img_targets = load_dataset('C:\\\\Users\\\\rock_paper_scissors')\n",
    "X, X_test, y, y_test = train_test_split(img, img_targets, test_size=0.2, random_state=42, shuffle=True, stratify=img_targets)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Printing the lengths to make sure they are no mistakes\n",
    "print('Total number of images: {}, Total number of labels: {}'.format(len(img), len(img_targets)))\n",
    "print('Total number of train images: {}, Total number of train labels: {}'.format(len(X_train), len(y_train)))\n",
    "print('Total number of validation images: {}, Total number of validation labels: {}'.format(len(X_validation), len(y_validation)))\n",
    "print('Total number of test images: {}, Total number of test labels: {}'.format(len(X_test), len(y_test)))\n",
    "\n",
    "# Transform train, validation and test data into tensor \n",
    "img_train = paths_to_tensor(X_train)\n",
    "img_valid = paths_to_tensor(X_validation)\n",
    "img_test = paths_to_tensor(X_test)\n",
    "\n",
    "\n",
    "# Setting some parameters \n",
    "top_model_weights_path = 'C:\\\\Users\\\\rock_paper_scissors.h5'\n",
    "epochs = 30\n",
    "batch_size = 25\n",
    "RMS = optimizers.RMSprop(lr=0.0001, rho=0.9)\n",
    "\n",
    "\n",
    "# Building the model\n",
    "new_model = Sequential()\n",
    "new_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=img_train.shape[1:], activation='relu'))\n",
    "new_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "new_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "new_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "new_model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "new_model.add(GlobalAveragePooling2D())\n",
    "new_model.add(Dense(250, activation='relu'))\n",
    "new_model.add(Dense(300, activation='relu'))\n",
    "new_model.add(Dropout(0.3))\n",
    "new_model.add(Dense(500, activation='relu'))\n",
    "new_model.add(Dropout(0.3))\n",
    "new_model.add(Dense(750, activation='relu'))\n",
    "new_model.add(Dropout(0.3))\n",
    "new_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "new_model.compile(optimizer=RMS,\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=top_model_weights_path, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=15)\n",
    "\n",
    "\n",
    "# Training the model\n",
    "new_model.fit(img_train, y_train,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(img_valid, y_validation),\n",
    "              callbacks=[checkpointer, early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Testing the model\n",
    "\n",
    "# Loading the weights of the trained top model\n",
    "new_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# Applying the top model to the bottleneck data and calculate test accuracy\n",
    "pred = [np.argmax(new_model.predict(np.expand_dims(pred_feat, axis=0))) for pred_feat in img_test]\n",
    "test_accuracy = 100*np.sum(np.array(pred)==np.argmax(y_test, axis=1))/len(pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART II: Assemble the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build functions to create the model and process the results\n",
    "\n",
    "def dl_recognition(top_model_weights_path = 'C:\\\\Users\\\\rock_paper_scissors.h5'):\n",
    "    \n",
    "    ## Build the model and import the weights\n",
    "    top_model_weights_path = top_model_weights_path\n",
    "\n",
    "    \n",
    "    # Building the model\n",
    "    new_model = Sequential()\n",
    "    new_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(240, 240, 3), activation='relu'))\n",
    "    new_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    new_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "    new_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    new_model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "    new_model.add(GlobalAveragePooling2D())\n",
    "    new_model.add(Dense(250, activation='relu'))\n",
    "    new_model.add(Dense(300, activation='relu'))\n",
    "    new_model.add(Dropout(0.3))\n",
    "    new_model.add(Dense(500, activation='relu'))\n",
    "    new_model.add(Dropout(0.3))\n",
    "    new_model.add(Dense(750, activation='relu'))\n",
    "    new_model.add(Dropout(0.3))\n",
    "    new_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "    # Loading the weights of the trained top model\n",
    "    new_model.load_weights(top_model_weights_path)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def results(prediction, opponent):\n",
    "    result = np.array([0,0,0])\n",
    "    \n",
    "    # Embed the rules of the game and count the results\n",
    "    if prediction == 0 and opponent == 1:\n",
    "        result[0] = 1\n",
    "    elif prediction == 1 and opponent == 2:\n",
    "        result[0] = 1\n",
    "    elif prediction == 2 and opponent == 0:\n",
    "        result[0] = 1\n",
    "    elif prediction == opponent:\n",
    "        result[1] = 1\n",
    "    else:\n",
    "        result[2] = 1\n",
    "            \n",
    "\n",
    "    return result\n",
    "\n",
    "def preprocess_img(frame):\n",
    "    img_model = cv2.resize(frame, (240,240))\n",
    "    img_model = cv2.cvtColor(img_model, cv2.COLOR_GRAY2RGB)\n",
    "    img_model = np.expand_dims(img_model, axis=0)\n",
    "    \n",
    "    return img_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the pieces to create the game\n",
    "\n",
    "bg = None\n",
    "opponent = random.randint(0,2)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "num_frames = 0\n",
    "count_result = np.array([0,0,0])\n",
    "model = dl_recognition()\n",
    "\n",
    "# keep looping, until interrupted\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Flip the frame so that it is not the mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Draw a rectangle to indicate the ROI\n",
    "    frame = cv2.rectangle(frame, (y1,x1), (y2,x2), (255,255,255), 3)\n",
    "    \n",
    "    # Get first image as background\n",
    "    if bg is None:\n",
    "        bg = cv2.cvtColor(frame[x1:x2,y1:y2], cv2.COLOR_BGR2GRAY)\n",
    "        bg = cv2.GaussianBlur(bg, (7,7), 0)\n",
    "        \n",
    "    roi = frame[x1:x2,y1:y2]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    roi = cv2.GaussianBlur(roi, (7,7), 0)\n",
    "    \n",
    "    # Use the BG and ROI to identify the hand gesture \n",
    "    diff = identify_hand(bg, roi)\n",
    "    \n",
    "    # Preprocess the image so it is model compliant\n",
    "    img_model = preprocess_img(diff)\n",
    "    \n",
    "    # Run the frame through the model so the player knows what (s)he is playing\n",
    "    visual = np.argmax(model.predict(img_model))\n",
    "    \n",
    "    # Run the game every 100 frames so player has time to strategize\n",
    "    if num_frames % 100 == 0:\n",
    "            prediction = np.argmax(model.predict(img_model))\n",
    "            opponent = random.randint(0,2)\n",
    "            result = results(prediction, opponent)\n",
    "            count_result += result \n",
    "\n",
    "    else:\n",
    "            opponent = opponent\n",
    "    \n",
    "    num_frames += 1\n",
    "    \n",
    "    # Print the information to player\n",
    "    frame = cv2.putText(frame, str('Opponent: ' + category_names[opponent]), (50,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "    frame = cv2.putText(frame, str('You: ' + category_names[visual]), (400,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)  \n",
    "    frame = cv2.putText(frame, str('win: ' + str(count_result[0])), (200,400), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "    frame = cv2.putText(frame, str('draw: ' + str(count_result[1])), (200,425), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "    frame = cv2.putText(frame, str('loss: ' + str(count_result[2])), (200,450), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "\n",
    "    # Show game screen\n",
    "    cv2.imshow('Game', frame)\n",
    "\n",
    "    # Close windows with Enter\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 13:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
